{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeerajHazarika/ENITS_DataMining_WS24/blob/main/Week_8/Assignment_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMa-bIfCtiTN"
      },
      "source": [
        "# Assignment: Credit Card Fraud Detection revised\n",
        "\n",
        "we return to the credit card use case (last time we used Random Forests).\n",
        "\n",
        "\n",
        "## Pre-Stage\n",
        "Use your pre-processing from the last assignment as input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": false,
        "id": "pPuTYzrttiTO",
        "outputId": "d48128df-af8c-4f7d-df01-0b2de7d70600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DATA' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#download data\n",
        "#get the data\n",
        "!git clone https://github.com/keuperj/DATA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eKvgn9kctiTO",
        "outputId": "c634ac71-dcc2-4bec-9a8e-5f6d214cbd5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DATA/creditcard.csv.zip\n",
            "replace creditcard.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!unzip DATA/creditcard.csv.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-QRcijH4tiTO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"creditcard.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print cols and rows and other stats abt data\n",
        "\n",
        "import pandas as pd\n",
        "# Print some info about the data\n",
        "print(data.info())\n",
        "print(\"\\nShape of the data:\")\n",
        "print(data.shape)\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(data.describe())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "FeQzhWykGkzG",
        "outputId": "8ed8d34f-2a3e-4a4f-8793-18f8b5b5ed61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n",
            "\n",
            "Shape of the data:\n",
            "(284807, 31)\n",
            "\n",
            "Descriptive Statistics:\n",
            "                Time            V1            V2            V3            V4  \\\n",
            "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
            "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
            "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
            "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
            "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
            "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
            "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
            "\n",
            "                 V5            V6            V7            V8            V9  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
            "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
            "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
            "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
            "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
            "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
            "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
            "\n",
            "       ...           V21           V22           V23           V24  \\\n",
            "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
            "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
            "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
            "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
            "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
            "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
            "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
            "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
            "\n",
            "                V25           V26           V27           V28         Amount  \\\n",
            "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
            "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
            "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
            "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
            "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
            "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
            "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
            "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
            "\n",
            "               Class  \n",
            "count  284807.000000  \n",
            "mean        0.001727  \n",
            "std         0.041527  \n",
            "min         0.000000  \n",
            "25%         0.000000  \n",
            "50%         0.000000  \n",
            "75%         0.000000  \n",
            "max         1.000000  \n",
            "\n",
            "[8 rows x 31 columns]\n",
            "\n",
            "First 5 rows:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9OcVyvfBtiTO"
      },
      "outputs": [],
      "source": [
        "# your preprocessing code\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop(['Class', 'Time', 'V1', 'Amount'], axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33lZDUI0tiTO"
      },
      "source": [
        "# Task: Train a MLP-Network\n",
        "* Train and evaluate the model\n",
        "* Compare the results to the Random Forrest\n",
        "* Tune the hyper-parameters (like number of layers, neurons per layer, learning-rate and number of epochs ) to optimize the results\n",
        "\n",
        "See: https://keras.io/api/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "k9uZwhboHs5k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tZNeGumdtiTO",
        "outputId": "fcb2538a-1bfa-4547-c03e-5984403dfe51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.0964 - val_accuracy: 0.9980 - val_loss: 0.0074\n",
            "Epoch 2/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0192 - val_accuracy: 0.9991 - val_loss: 0.0041\n",
            "Epoch 3/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0129 - val_accuracy: 0.9993 - val_loss: 0.0030\n",
            "Epoch 4/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0096 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
            "Epoch 5/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
            "Epoch 6/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0075 - val_accuracy: 0.9995 - val_loss: 0.0024\n",
            "Epoch 7/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9996 - val_loss: 0.0019\n",
            "Epoch 8/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.9997 - val_loss: 0.0017\n",
            "Epoch 9/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
            "Epoch 10/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0055 - val_accuracy: 0.9997 - val_loss: 0.0020\n",
            "Epoch 11/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0048 - val_accuracy: 0.9997 - val_loss: 0.0018\n",
            "Epoch 12/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0048 - val_accuracy: 0.9997 - val_loss: 0.0018\n",
            "Epoch 13/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
            "Epoch 14/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9997 - val_loss: 0.0014\n",
            "Epoch 15/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.9998 - val_loss: 0.0018\n",
            "Epoch 16/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0038 - val_accuracy: 0.9998 - val_loss: 0.0014\n",
            "Epoch 17/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9997 - val_loss: 0.0012\n",
            "Epoch 18/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9997 - val_loss: 0.0015\n",
            "Epoch 19/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
            "Epoch 20/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0036 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
            "Epoch 21/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
            "Epoch 22/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9997 - val_loss: 0.0015\n",
            "Epoch 23/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
            "Epoch 24/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
            "Epoch 25/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9998 - val_loss: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
            "Epoch 27/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
            "Epoch 28/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9997 - val_loss: 0.0013\n",
            "Epoch 29/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
            "Epoch 30/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0030 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
            "Epoch 31/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9997 - val_loss: 0.0012\n",
            "Epoch 32/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9998 - val_loss: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9998 - val_loss: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9996 - val_loss: 0.0016\n",
            "Epoch 35/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
            "Epoch 36/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
            "Epoch 37/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9998 - val_loss: 0.0011\n",
            "Epoch 38/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9998 - val_loss: 0.0012\n",
            "Epoch 39/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.9999 - val_loss: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9999 - val_loss: 0.0012\n",
            "Epoch 41/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.9998 - val_loss: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9999 - val_loss: 9.6082e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9999 - val_loss: 9.4284e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9998 - val_loss: 8.6839e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.9998 - val_loss: 9.7223e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0026 - val_accuracy: 0.9998 - val_loss: 9.6901e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9998 - val_loss: 9.6456e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9998 - val_loss: 8.4537e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9998 - val_loss: 8.1242e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m5687/5687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9997 - val_loss: 0.0013\n",
            "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
            "Test Loss: 0.0012\n",
            "Test Accuracy: 0.9998\n",
            "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
            "Optimal Threshold: 0.9534034729003906\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56863\n",
            "           1       1.00      1.00      1.00     56863\n",
            "\n",
            "    accuracy                           1.00    113726\n",
            "   macro avg       1.00      1.00      1.00    113726\n",
            "weighted avg       1.00      1.00      1.00    113726\n",
            "\n",
            "ROC-AUC Score: 1.0000\n",
            "F1-Score: 0.9998\n"
          ]
        }
      ],
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Handle class imbalance: SMOTE + NearMiss\n",
        "smote = SMOTE(random_state=42)\n",
        "nearmiss = NearMiss()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Define the MLP model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile with Adam optimizer and Focal Loss\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Predict probabilities and tune threshold\n",
        "y_pred_probs = model.predict(X_test)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
        "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
        "\n",
        "# Use the optimal threshold for predictions\n",
        "y_pred = (y_pred_probs > optimal_threshold).astype(\"int32\")\n",
        "\n",
        "# Classification Report and Metrics\n",
        "print(classification_report(y_test, y_pred))\n",
        "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "mlp_f1 = report['1']['f1-score']\n",
        "\n",
        "#Compare with random forest\n",
        "random_forest_f1 = 0.8516129032258064\n",
        "print(f\"\\nMLP F1-score: {mlp_f1}\")\n",
        "print(f\"Random Forest F1-score: {random_forest_f1}\")\n",
        "\n",
        "if mlp_f1 > random_forest_f1:\n",
        "    print(\"MLP model outperforms Random Forest.\")\n",
        "elif mlp_f1 < random_forest_f1:\n",
        "    print(\"Random Forest outperforms MLP model.\")\n",
        "else:\n",
        "    print(\"MLP model and Random Forest perform equally.\")"
      ],
      "metadata": {
        "id": "dlSp6BNLvoqZ",
        "outputId": "858897d7-9a23-46e0-c2e0-790ee3fb636d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MLP F1-score: 0.9998417471118848\n",
            "Random Forest F1-score: 0.8516129032258064\n",
            "MLP model outperforms Random Forest.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}